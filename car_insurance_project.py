# -*- coding: utf-8 -*-
"""Car_Insurance_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/177uBuH08TIzSuHx6x_z6jo8pzmAuzTuu

#Car Insurance Claim Prediction

## By Ridwan Adeniyi

## Introduction

This project is all about building a model that can predict whether a customer will make an insurance claim. Starting from the raw dataset, I worked through cleaning the data, exploring patterns, creating useful features, and testing different machine-learning approaches.


I used techniques like frequency encoding, one-hot encoding, and a Random Forest model to improve performance. I also evaluated the model using validation metrics and a custom revenue curve to see how well it would work in a real business setting.

#Importing Libraries

This section loads all the libraries used throughout the project, including tools for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn), and machine learning (scikit-learn).
"""

import pandas as pd               # Data manipulation and analysis
import numpy as np                # Numerical computing

import matplotlib.pyplot as plt   # Plotting and visualization
import seaborn as sns             # Statistical data visualization
sns.set_theme()                   # Apply a clean default theme for plots

# Model training, splitting, and preprocessing
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# Encoding, scaling, and base preprocessors
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder

# Machine learning models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Evaluation metrics and utilities
from sklearn.metrics import (
    accuracy_score, roc_auc_score, RocCurveDisplay,
    confusion_matrix, roc_curve
)

import sklearn.metrics as metrics # Additional metric access

# Custom estimator/transformer support
from sklearn.base import BaseEstimator, TransformerMixin

"""#Loading the Training & Test Data

I import the project datasets from Excel files. The training dataset will be used to build and validate the model, while the test dataset will be used to generate final predictions.
"""

# Load the training dataset from Excel
training_data = pd.read_excel('/content/Project2_Training.xlsx')
training_data   # Display the training data

# Load the test dataset from Excel
test_data = pd.read_excel('/content/Project2_Test.xlsx')
test_data       # Display the test data

training_data.shape

training_data.columns

print("\nColumn names:\n", training_data.columns.tolist())

"""#Data Cleaning & Preprocessing Summary

###This section performs the full cleaning workflow:
	​

**1. Column Standardization**

*   Lowercasing

*   Removing spaces

*   Preparing consistent column names

	​
**2. Categorical Fixes**

*   Remove non-vehicle gibberish entries

	​
**3. Outlier & Invalid Value Handling**

*   Impossible years

*   Unrealistic vehicle value

*   Excessive annual mileage

	​
**4. Joint Imputation for Annual KM & Commute Distance**

Using:

factor = sum
(annual_km) / sum
(commute_distance)

	​
**5. Fill missing categorical fields**
*   Fill the marking_system and tracking_system with None, and the occupation with Not Known.

	​
**6. Vehicle model Fixes**

*   Clean vehicle make / model

*   Fix typos, normalize brand names

	​
**7. Date Encoding**

*   Convert quotedate to days since earliest date.

	​
**8. Drop columns with high missing value**

*   years_as_principal_driver
*   vehicle_ownership

	​
**9. Final Imputation**

*   Numeric - median

*   Categorical - "Unknown"

I created a function to house all the data preprocessing to aid a very clean preprocessing step and to prevent any data leakage while exerting on the test dataset.
"""

def preprocess_data(df, is_train=True):
    """
    Complete preprocessing pipeline for Insurance Modeling.

    Parameters
    ----------
    df : pd.DataFrame
        Raw data
    is_train : bool
        If True → preserves target column "is_bound"
        If False → skips operations that rely on target

    Returns
    -------
    df : cleaned DataFrame ready for modeling or prediction
    """

    df = df.copy()



    # 1. CLEAN COLUMN NAMES

    df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")




    # 2. REMOVE JUNK VEHICLE MAKES

    gibberish_makes = [
        "1FTFW1EF8BFA01523", "2XXXXXXXXXXXXXXXXXX", "UNDISCLOSED",
        "RYMCO", "MOBILITY", "SCOOTTERRE", "TRIPLE", "TRAVEL",
        "EL", "BLUE", "HIGH", "NEW", "TRAIL", "CONVERTED", "STREET"
    ]

    if "vehiclemake" in df.columns:
        df = df[~df["vehiclemake"].isin(gibberish_makes)]




    # 3. OUTLIERS & SANITY CHECKS

    if "year_of_birth" in df:
        df.loc[~df.year_of_birth.between(1920, 2005), "year_of_birth"] = np.nan

    if "vehicleyear" in df:
        df.loc[~df.vehicleyear.between(1980, 2025), "vehicleyear"] = np.nan

    if "vehicle_value" in df:
        df.loc[df.vehicle_value < 500, "vehicle_value"] = np.nan

    if "annual_km" in df:
        df.loc[df.annual_km > 200000, "annual_km"] = np.nan

    if "commute_distance" in df:
        df.loc[df.commute_distance > 200, "commute_distance"] = np.nan




    # 4. IMPUTE commute_distance AND annual_km

    if ("annual_km" in df) and ("commute_distance" in df):
        valid = df["annual_km"].notna() & df["commute_distance"].notna()

        if valid.sum() > 0:
            factor = (
                df.loc[valid, "annual_km"].sum() /
                df.loc[valid, "commute_distance"].sum()
            )

            df["commute_distance"] = df["commute_distance"].fillna(
                df["annual_km"] / factor
            )
            df["annual_km"] = df["annual_km"].fillna(
                df["commute_distance"] * factor
            )

    # Convert only if column exists
    for col in ["annual_km", "commute_distance"]:
        if col in df:
            df[col] = df[col].astype(float).round().astype("Int64")




    # 5. FILL CATEGORICAL MISSINGNESS

    fill_none_cols = ["marking_system", "tracking_system"]
    for col in fill_none_cols:
        if col in df:
            df[col] = df[col].fillna("None")

    if "occupation" in df:
        df["occupation"] = df["occupation"].fillna("Not Known")




    # 6. VEHICLE TYPE + MAKE/MODEL NORMALIZATION

    if "vehiclemake" in df:

        # Vehicle type
        df["vehicletype"] = np.where(
            df["vehiclemake"].str.contains("VAN", na=False),
            "VAN",
            "CAR"
        )

        # Clean make token
        df["vehiclemake"] = df["vehiclemake"].astype(str).str.split().str[0]

        # Map model-as-make errors
        model_to_make_map = {
            "ALTIMA": "NISSAN", "ASTRO": "CHEVROLET", "CAMRY": "TOYOTA",
            "CELICA": "TOYOTA", "CHALLENGER": "DODGE", "CIVIC": "HONDA",
            "COROLLA": "TOYOTA", "CORROLLA": "TOYOTA",
            "CORVETTE": "CHEVROLET", "CUTLASS": "OLDSMOBILE",
            "E350": "FORD", "ELANTRA": "HYUNDAI",
            "F150": "FORD", "F250": "FORD",
            "GRAND": "DODGE", "JETTA": "VOLKSWAGEN",
            "MAILBOU": "CHEVROLET", "MATRIX": "TOYOTA",
            "MAZDA3": "MAZDA", "MGA": "MG", "MGB": "MG",
            "MONTANA": "PONTIAC", "MUSTANG": "FORD",
            "PASSAT": "VOLKSWAGEN", "RANGER": "FORD",
            "SIERRA": "GMC", "SPRINT": "CHEVROLET",
            "VUE": "SATURN", "Z28": "CHEVROLET",
        }

        rows_to_fix = df["vehiclemake"].isin(model_to_make_map.keys())
        df.loc[rows_to_fix, "vehiclemodel"] = df.loc[rows_to_fix, "vehiclemake"]
        df.loc[rows_to_fix, "vehiclemake"] = df["vehiclemake"].map(model_to_make_map)

        # Fix typos
        typo_map = {"CORROLLA": "COROLLA", "MAILBOU": "MALIBU"}
        if "vehiclemodel" in df:
            df["vehiclemodel"] = df["vehiclemodel"].replace(typo_map)

        # spelling normalization
        spelling_replace_map = {
            "VW": "VOLKSWAGEN", "WV": "VOLKSWAGEN",
            "VOLKSWAGON": "VOLKSWAGEN",
            "VOLGSWAGEN": "VOLKSWAGEN", "VOLSWAGEN": "VOLKSWAGEN",
            "HUNDAY": "HYUNDAI", "HUNDAI": "HYUNDAI", "HYNDAI": "HYUNDAI",
            "CHEV": "CHEVROLET", "CHEVY": "CHEVROLET",
            "NISSIAN": "NISSAN", "NISASN": "NISSAN",
            "MITIBUSHI": "MITSUBISHI", "HONODA": "HONDA",
            "ACCURA": "ACURA", "PORCHE": "PORSCHE"
        }

        df["vehiclemake"] = df["vehiclemake"].replace(spelling_replace_map)




    # 7. DATE ENCODING

    if "quotedate" in df:
        min_date = df["quotedate"].min()
        df["quotedate"] = (df["quotedate"] - min_date).dt.days




    # 8. DROP UNUSED COLUMNS

    drop_cols = ["years_as_principal_driver", "vehicle_ownership"]
    df = df.drop([c for c in drop_cols if c in df], axis=1)




    # 9. FINAL NUMERIC & CATEGORICAL IMPUTATION

    num_cols = df.select_dtypes(include=np.number).columns
    cat_cols = df.select_dtypes(exclude=np.number).columns

    df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce")
    df[num_cols] = df[num_cols].fillna(df[num_cols].median())
    df[cat_cols] = df[cat_cols].fillna("Unknown")

    return df

"""Aligning the datasets to having same feature names

The test dataset has feature names different from that of the training set. Therefore, i aligned the features to have same names for easy preprocessing.
"""

# Get feature column names from training_data
new_feature_names = [c for c in training_data.columns if c != 'IS_BOUND']

# Rename df1 columns
test_data.columns = new_feature_names

"""### Calling function on training data"""

training_data = preprocess_data(training_data, is_train=True)

"""### Calling function on test data"""

test_data = preprocess_data(test_data, is_train=False)

"""#Feature Encoding and Selection


I split the dataset into training and validation sets. All columns removed are not model inputs.
"""

X = training_data.drop(columns=['is_bound'])  # Features
y = training_data['is_bound']                 # Target variable


X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.25,        # 25% for testing, 75% for training
    random_state=42,      # for reproducibility
    stratify=y            # keeps class distribution same as original (for classification)
)

"""I encoded my categorical variables using both one-hot encoding and frequency encoding depending on the number of unique variables they have."""

# Define column types
num_cols = [
    'vehicleyear', 'vehicle_value', 'year_of_birth', 'years_licensed',
    'conviction_count_minor_3yrs', 'annual_km', 'commute_distance',
    'conviction_count_criminal_3yrs', 'suspension_count',
    'assigned_losses_pd_5yrs',  'conviction_count_major_3yrs'
]
onehot_cols = ['marking_system', 'tracking_system', 'vehicleuse', 'gender', 'marital_status', 'vehicletype', 'multi_product']     # unordered, few categories
freq_cols = ['quotedate', 'vehiclemake', 'vehiclemodel','postal_code', 'area_code','occupation']     # unordered, many categories

"""#Frequency Encoding for High-Cardinality Categorical Features

Some categorical variables contain many unique values, which can make one-hot encoding inefficient.
To handle this, i apply frequency encoding, replacing each category with how often it appears in the dataset.

This helps the model learn patterns while keeping the feature space compact.
"""

# Frequency encoding function

# This function replaces categorical values with their frequency counts.
# It ensures the same mapping is applied to both the training and test sets.
def frequency_encode(train, test, cols):
    for col in cols:
        # Count frequency of each category in the training data
        freq = train[col].value_counts()

        # Map frequencies to training data
        train[col + '_encoded'] = train[col].map(freq)

        # Map frequencies to test data (fill unseen categories with 0)
        test[col + '_encoded'] = test[col].map(freq).fillna(0)

    return train, test

# Apply frequency encoding to selected columns
X_train, X_test = frequency_encode(X_train, X_test, freq_cols)

"""#Building Preprocessing Pipelines

To prepare the dataset for modeling, i create separate pipelines for numeric and categorical features.
Each pipeline handles missing values and applies transformations suited to its feature type.
"""

# Build pipelines for numeric and one-hot features
num_pipeline = Pipeline([
    ('impute', SimpleImputer(strategy='median'))
])

onehot_pipeline = Pipeline([
    ('impute', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combine pipelines with ColumnTransformer
preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_cols),
    ('onehot', onehot_pipeline, onehot_cols),
    ('freq', 'passthrough', [col + '_encoded' for col in freq_cols])
])

"""#Extracting and Ranking Feature Importance

I would be training a Random Forest model to help extract the feature importances to understand which variables contributed most to predictions.
This would help us reduce the parameters introduced into the model which in turns help reduce overfitting.
"""

# Build full pipeline with Random Forest
model_pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Train model
model_pipeline.fit(X_train, y_train)

# Predict & evaluate
y_pred = model_pipeline.predict(X_test)
y_prob = model_pipeline.predict_proba(X_test)[:, 1]

print("Accuracy:", accuracy_score(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_prob))

"""### Testing for feature importance"""

# Get the trained Random Forest model from the pipeline
rf_model = model_pipeline.named_steps['rf']

# Get the preprocessor to know final feature names
preprocessor = model_pipeline.named_steps['preprocess']

# Numeric columns after scaling
num_features = num_cols

# One-hot encoded columns
onehot_features = preprocessor.named_transformers_['onehot']['encode'].get_feature_names_out(onehot_cols)

# Frequency encoded columns
freq_features = [col + '_encoded' for col in freq_cols]

# Combine all feature names
all_features = np.concatenate([num_features, onehot_features, freq_features])

# Get feature importances from Random Forest
importances = rf_model.feature_importances_

# Create a DataFrame for ranking
feature_importance_df = pd.DataFrame({
    'Feature': all_features,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Display ranking
print(feature_importance_df)

"""From the feature importance above, i could note that tracking_system, marking_system, vehicle_use, and conviction_count_major_3yrs are the least important features.

#Splitting Data Into Training and Validation Sets

In this section, i remove columns that should not be used for modeling, separate the target variable, and split the dataset into training and validation subsets.
The split is stratified to preserve the proportion of the target classes in both sets.
"""

# Preparing Features and Splitting Into Train/Validation Sets


# Drop unused or leakage-prone columns from the training data
X = training_data.drop(columns=[
    'is_bound',                    # target variable (removed from features)
    'tracking_system',             # excluded feature
    'vehicleuse',                  # excluded feature
    'marking_system',              # excluded feature
    'conviction_count_major_3yrs'  # excluded feature
])

# Extract the target variable
y = training_data['is_bound']

# Split data into training and validation subsets
X_train, X_valid, y_train, y_valid = train_test_split(
    X, y,
    test_size=0.25,       # 25% validation
    random_state=42,      # ensures reproducibility
    stratify=y            # keeps class distribution consistent
)

"""#Column Groups

Redefine columns for frequency encoding.
"""

#Redefine columns
num_cols = [
    'vehicleyear', 'vehicle_value', 'year_of_birth', 'years_licensed',
    'conviction_count_minor_3yrs', 'annual_km', 'commute_distance',
    'conviction_count_criminal_3yrs', 'suspension_count',
    'assigned_losses_pd_5yrs'
]

onehot_cols = ['gender', 'marital_status', 'vehicletype', 'multi_product']

freq_cols = [
    'quotedate', 'vehiclemake', 'vehiclemodel',
    'postal_code', 'area_code', 'occupation'
]

# Ensure all categorical columns are strings
for col in onehot_cols:
    X_train[col] = X_train[col].astype(str)
    X_valid[col] = X_valid[col].astype(str)

for col in freq_cols:
    X_train[col] = X_train[col].astype(str)
    X_valid[col] = X_valid[col].astype(str)

"""Apply frequency encoding to the split after dropping some features"""

# Apply frequency encoding to selected columns
X_train, X_valid = frequency_encode(X_train, X_valid, freq_cols)

"""#Preprocessing Pipelines

I create transformations for numeric, categorical (one-hot), and frequency-encoded columns.
"""

num_pipe = Pipeline([
    ('impute', SimpleImputer(strategy='median')),
    ('scale', StandardScaler())
])

onehot_pipe = Pipeline([
    ('impute', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer([
    ('num', num_pipe, num_cols),
    ('cat', onehot_pipe, onehot_cols),
    ('freq', 'passthrough', [c + '_encoded' for c in freq_cols])
])

"""#Logistic Regression Training

Train a penalized logistic regression model with L1 regularization.
"""

# Identify numeric and categorical columns
numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()

# Preprocessing pipelines
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_cols),
    ('cat', categorical_transformer, categorical_cols)
])

# Full pipeline with logistic regression
lr_model = Pipeline([
    ('preprocess', preprocessor),
    ('model', LogisticRegression(max_iter=1000, class_weight='balanced'))
])

# Fit
lr_model.fit(X_train, y_train)

# Predict probabilities
log_valid_proba = lr_model.predict_proba(X_valid)[:, 1]

# ROC AUC
from sklearn.metrics import roc_auc_score
log_auc = roc_auc_score(y_valid, log_valid_proba)
print("Logistic Regression AUC:", log_auc)

"""#Random Forest Training

Train a Random Forest classifier with class balancing and tuned hyperparameters.
"""

rf_model = Pipeline([
    ('prep', preprocessor),
    ('model', RandomForestClassifier(
        n_estimators=900,
        min_samples_leaf=5,
        n_jobs=-1,
        class_weight='balanced',
        random_state=42
    ))
])

rf_model.fit(X_train, y_train)
rf_valid_proba = rf_model.predict_proba(X_valid)[:, 1]

rf_auc = roc_auc_score(y_valid, rf_valid_proba)
print("Random Forest AUC:", rf_auc)

"""#Plot ROC Curves

###Compare logistic regression and random forest visually.
"""

fpr_log, tpr_log, _ = roc_curve(y_valid, log_valid_proba)
fpr_rf, tpr_rf, _ = roc_curve(y_valid, rf_valid_proba)

plt.figure(figsize=(7,7))
plt.plot(fpr_log, tpr_log, label=f"Logistic (AUC={log_auc:.3f})")
plt.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC={rf_auc:.3f})")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves — Logistic vs Random Forest")
plt.legend()
plt.grid(True)
plt.show()

"""From this, It is obvious that Random Forest performed better than the Logistic Regression model. Therefore, I selected Random Forest to be used for the predictions.

#Revenue Functions

The business objective: maximize revenue = 5.5 × TP − 1 × PredictedPositives.

advertising_revenue() - Computes revenue at a single threshold

This function evaluates how profitable the model is for a specific probability threshold.
"""

def advertising_revenue(y_true, y_proba, threshold):
    y_pred = (y_proba >= threshold).astype(int)
    tp = np.sum((y_pred == 1) & (y_true == 1))
    pred_pos = np.sum(y_pred == 1)
    return 5.5 * tp - 1.0 * pred_pos

"""This converts probabilities into binary predictions using the threshold.

Counts:

*   True Positives (TP) – each earns $5.50

*   All predicted positives (TP + FP) – each costs $1.00

Returns the net revenue:

*   Revenue = 5.5 × TP − 1.0 × (Predicted Positive)

This reflects the business goal: maximize profitable correct predictions while minimizing unnecessary ads.

###compute_revenue_curve() - Tests thresholds from 0 to 1

This function evaluates revenue at 201 different thresholds (0.00, 0.005, 0.01, … , 1.00).
"""

def compute_revenue_curve(y_true, y_proba):
    thr = np.linspace(0, 1, 201)
    rev = [advertising_revenue(y_true, y_proba, t) for t in thr]
    return thr, np.array(rev)

"""This sweeps through many threshold values, computes revenue at each threshold, and returns everything needed to plot the Revenue vs Threshold curve.

#Compute & Plot Revenue Curves
"""

# Logistic revenue curve
thr_grid, rev_log = compute_revenue_curve(y_valid, log_valid_proba)

# Random Forest revenue curve
_, rev_rf = compute_revenue_curve(y_valid, rf_valid_proba)

# Best thresholds by max revenue
best_log_idx = np.argmax(rev_log)
best_rf_idx = np.argmax(rev_rf)

best_threshold_log = thr_grid[best_log_idx]
best_threshold_rf = thr_grid[best_rf_idx]

best_rev_log = rev_log[best_log_idx]
best_rev_rf = rev_rf[best_rf_idx]

print(f"Best Logistic: best threshold = {best_threshold_log:.3f}, best revenue = {best_rev_log:.2f}")
print(f"Best Random Forest: best threshold = {best_threshold_rf:.3f}, best revenue = {best_rev_rf:.2f}")

# Plot revenue vs threshold
plt.figure(figsize=(8,5))
plt.plot(thr_grid, rev_log, label=f"Logistic best={best_threshold_log:.2f}")
plt.plot(thr_grid, rev_rf, label=f"RF best={best_threshold_rf:.2f}")
plt.axvline(1/5.5, linestyle='--', label="Theoretical 0.18")
plt.xlabel("Threshold")
plt.ylabel("Revenue")
plt.title("Advertising Revenue vs Threshold")
plt.legend()
plt.grid(True)
plt.show()

"""#Refit Final Model on FULL Training Data"""

# Copy full data
X_full = X.copy()
y_full = y.copy()

# Apply frequency encoding
X_full_encoded, test_encoded = frequency_encode(X_full, test_data, freq_cols)

# Identify numeric and categorical columns
numeric_cols = X_full_encoded.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = X_full_encoded.select_dtypes(include=['object']).columns.tolist()

# Ensure all categorical columns are strings
for col in categorical_cols:
    X_full_encoded[col] = X_full_encoded[col].astype(str)
    test_encoded[col] = test_encoded[col].astype(str)

# Frequency-encoded columns (numeric)
freq_encoded_cols = [c + "_encoded" for c in freq_cols]
for col in freq_encoded_cols:
    X_full_encoded[col] = X_full_encoded[col].astype(float)
    test_encoded[col] = test_encoded[col].astype(float)

# Preprocessing pipelines
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median'))
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_cols),
    ('cat', categorical_transformer, categorical_cols),
    ('freq', 'passthrough', freq_encoded_cols)
])

# Random Forest pipeline
rf_full_pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('model', RandomForestClassifier(
        n_estimators=900,
        min_samples_leaf=5,
        class_weight='balanced',
        n_jobs=-1,
        random_state=42
    ))
])

# Fit on full training data
rf_full_pipeline.fit(X_full_encoded, y_full)

# Predict on test set
test_pred_proba = rf_full_pipeline.predict_proba(test_encoded)[:, 1]
test_pred_class = (test_pred_proba >= best_threshold_rf).astype(int)

"""#Exporting Final Predictions
After selecting the best model and the optimal revenue-maximizing threshold, I apply this threshold to the test-set probabilities to generate final class predictions.
The predictions are printed with an increased array display limit so the entire output is visible.
"""

# Apply final threshold
np.set_printoptions(threshold=20000)
print("Predictions:", test_pred_class.tolist())

# Performance on Gradescope leaderboard

values = [[52, 27, 52, 17]]

result = pd.DataFrame(values, columns=[
    "Accuracy", "False Negative Rate", "False Positive Rate", "Advertising Revenue"
])

print(result)